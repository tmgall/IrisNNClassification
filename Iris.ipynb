{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: \n",
    "# reg_param stands for regularization parameter\n",
    "# mathematically, lambda is usually used, but, in Python, lambda has a different meaning\n",
    "# as a result reg_param is used to represent this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data as a pandas DataFrame\n",
    "data = pd.read_csv('iris.data.txt', header=None)\n",
    "\n",
    "# label data columns\n",
    "data.columns = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"class\"]\n",
    "\n",
    "# create a list of the different iris classes\n",
    "labels = list(data['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test algorithm with different sets, run this cell\n",
    "\n",
    "# some useful values for the set\n",
    "training_set_proportion = 0.7\n",
    "set_size = data.shape[0]\n",
    "training_set_size = int(training_set_proportion*set_size)\n",
    "test_set_size = set_size - training_set_size\n",
    "\n",
    "# shuffle data and input bias unit\n",
    "shuffled = data.sample(frac=1)\n",
    "shuffled.insert(0, 'bias', np.ones(set_size))\n",
    "# NOTE: to view data, call \"data\" for organized data or \"shuffled\" for randomized data with bias unit\n",
    "\n",
    "# use the take(np.array) function to divide randomized rows into training and test sets \n",
    "training_indices = np.zeros(training_set_size)\n",
    "test_indices = np.zeros(test_set_size)\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "for i in training_indices:\n",
    "    training_indices[counter1] = counter1\n",
    "    counter1 += 1\n",
    "for i in test_indices:\n",
    "    test_indices[counter2] = counter1\n",
    "    counter1 += 1\n",
    "    counter2 += 1\n",
    "training_set = shuffled.take(training_indices) # DataFrame with (training_set_size) random examples\n",
    "test_set = shuffled.take(test_indices) # DataFrame with (test_set_size) random examples unique from training_set\n",
    "\n",
    "# create pandas Series for training labels and test labels with string datatype\n",
    "training_labels_strings = training_set.pop('class')\n",
    "test_labels_strings = test_set.pop('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful values\n",
    "m = training_set.shape[0]\n",
    "num_input_nodes = training_set.shape[1]\n",
    "num_hidden_nodes = 3\n",
    "num_output_nodes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matrices with binary values for class labels instead of strings\n",
    "training_labels = np.zeros((m, len(labels)), dtype=int)\n",
    "test_labels = np.zeros((test_set.shape[0], len(labels)), dtype=int)\n",
    "for i in range(m):\n",
    "    flower_type = np.array(training_labels_strings.take([i]))[0]\n",
    "    if (flower_type == labels[0]):\n",
    "        training_labels[i][0] = 1\n",
    "    if (flower_type == labels[1]):\n",
    "        training_labels[i][1] = 1\n",
    "    if (flower_type == labels[2]):\n",
    "        training_labels[i][2] = 1\n",
    "for i in range(test_set.shape[0]):\n",
    "    flower_type = np.array(test_labels_strings.take([i]))[0]\n",
    "    if (flower_type == labels[0]):\n",
    "        test_labels[i][0] = 1\n",
    "    if (flower_type == labels[1]):\n",
    "        test_labels[i][1] = 1\n",
    "    if (flower_type == labels[2]):\n",
    "        test_labels[i][2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sets to numpy array and shorten name for ease later\n",
    "train = np.array(training_set)\n",
    "test = np.array(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create theta\n",
    "theta1_shape = (num_hidden_nodes, num_input_nodes)\n",
    "theta1 = np.zeros(theta1_shape)\n",
    "theta2_shape = (num_output_nodes, num_hidden_nodes + 1)\n",
    "theta2 = np.zeros(theta2_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize theta using small, random values to avoid symmetry\n",
    "def initializeTheta(theta1, theta2, initialization_range=1e-3):\n",
    "    for i in range(theta1.shape[0]):\n",
    "        for j in range(theta1.shape[1]):\n",
    "            random_number = (np.random.rand() - 0.5) * initialization_range\n",
    "            theta1[i][j] = random_number\n",
    "    for i in range(theta2.shape[0]):\n",
    "        for j in range(theta2.shape[1]):\n",
    "            random_number = (np.random.rand() - 0.5) * initialization_range\n",
    "            theta2[i][j] = random_number\n",
    "    return (theta1, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sig(x):\n",
    "    return 1/(1+np.exp(-1*x))\n",
    "def sigmoid(z):\n",
    "    length = z.flatten().size\n",
    "    result = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        result[i] = sig(z.flatten()[i])\n",
    "    result = np.reshape(result, z.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "def cost(train, training_labels, theta1, theta2, reg_param):\n",
    "    num_input_nodes = train[0]\n",
    "    num_output_nodes = training_labels[1].size\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        a1 = train[i]\n",
    "        z2 = np.dot(theta1, a1)\n",
    "        a2 = np.insert(sigmoid(z2), 0, 1)\n",
    "        z3 = np.dot(theta2, a2)\n",
    "        a3 = sigmoid(z3).flatten()\n",
    "        for k in range(num_output_nodes):\n",
    "            yi_k = training_labels[i][k]\n",
    "            pred_k = a3[k]\n",
    "            J += -1*(yi_k * np.log(pred_k) + (1 - yi_k) * np.log(1 - pred_k))\n",
    "    # regularization\n",
    "    for i in range(theta1.flatten().size):\n",
    "        J += reg_param / 2 * theta1.flatten()[i]**2\n",
    "    for i in range(theta2.flatten().size):\n",
    "        J += reg_param / 2 * theta2.flatten()[i]**2\n",
    "    J /= m\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backpropagation\n",
    "def backprop(train, training_labels, theta1, theta2, reg_param):\n",
    "    grad1 = np.zeros(theta1.shape)\n",
    "    grad2 = np.zeros(theta2.shape)\n",
    "    # backpropagate\n",
    "    for i in range(m):\n",
    "        a1 = train[i][:,None]\n",
    "        z2 = np.dot(theta1, a1)\n",
    "        a2 = np.insert(sigmoid(z2.flatten()), 0, 1)[:,None]\n",
    "        z3 = np.dot(theta2, a2)\n",
    "        a3 = sigmoid(z3).flatten()\n",
    "        delta3 = np.subtract(a3, training_labels[i])[:,None]\n",
    "        delta2 = np.multiply(np.dot(theta2.T, delta3), np.multiply(a2, np.subtract(np.ones(a2.shape), a2)))\n",
    "        delta2 = delta2[1:len(delta2)]\n",
    "        grad2 = np.add(grad2, np.dot(delta3, a2.T))\n",
    "        grad1 = np.add(grad1, np.dot(delta2, a1.T))\n",
    "    # regularization\n",
    "    for i in range(grad1.shape[0]):\n",
    "        for j in range(grad1.shape[1]):\n",
    "            grad1[i][j] /= m\n",
    "            if (j > 0):\n",
    "                grad1[i][j] += reg_param * theta1[i][j]\n",
    "    for i in range(grad2.shape[0]):\n",
    "        for j in range(grad2.shape[1]):\n",
    "            grad2[i][j] /= m\n",
    "            if (j > 0):\n",
    "                grad2[i][j] += reg_param * theta2[i][j]\n",
    "    return (grad1, grad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "def train_network(train, training_labels, theta1, theta2, reg_param, alpha, iterations=1000, updates=False):\n",
    "    (theta1, theta2) = initializeTheta(theta1, theta2)\n",
    "    for i in range(iterations):\n",
    "        (grad1, grad2) = backprop(train, training_labels, theta1, theta2, reg_param)\n",
    "        grad1 = np.multiply(grad1, alpha)\n",
    "        grad2 = np.multiply(grad2, alpha)\n",
    "        theta1 = np.subtract(theta1, grad1)\n",
    "        theta2 = np.subtract(theta2, grad2)\n",
    "        if (updates):\n",
    "            if (i % 1000 == 0):\n",
    "                print(cost(train, training_labels, theta1, theta2, reg_param))\n",
    "    return (theta1, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy of theta\n",
    "def test_theta(test, test_labels, theta1, theta2):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(test)):\n",
    "        a1 = test[i][:,None] # (5, 1)\n",
    "        z2 = np.dot(theta1, a1)\n",
    "        a2 = np.insert(sigmoid(z2.flatten()), 0, 1)[:,None] # (4, 1)\n",
    "        z3 = np.dot(theta2, a2)\n",
    "        a3 = sigmoid(z3).flatten()\n",
    "        if (predict(a3) == predict(test_labels[i])):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict most likely class\n",
    "def predict(choices):\n",
    "    result = 0\n",
    "    maximum = 0\n",
    "    for i in range(choices.size):\n",
    "        if choices[i] > maximum:\n",
    "            maximum = choices[i]\n",
    "            result = i\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.93 and Cost = 0.82958 (0.001, 0.1)\n",
      "Best: 0.9333333333333333\n",
      "Regularization: 0.001\n",
      "Alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "# test best values for reg_param and alpha\n",
    "# values below have tested best for accuracy\n",
    "reg_params = [0.001]\n",
    "alphas = [0.1]\n",
    "# to test more values, add to above arrays\n",
    "\n",
    "# test accuracy based on each combination of reg_param and alpha\n",
    "best_accuracy = 0\n",
    "best_reg_param = reg_params[0]\n",
    "best_alpha = alphas[0]\n",
    "for reg_param in reg_params:\n",
    "    for alpha in alphas:\n",
    "        (theta1, theta2) = train_network(train, training_labels, theta1, theta2, reg_param, alpha)\n",
    "        accuracy = test_theta(test, test_labels, theta1, theta2)\n",
    "        J = cost(train, training_labels, theta1, theta2, reg_param)\n",
    "        if (accuracy > best_accuracy):\n",
    "            best_accuracy = accuracy\n",
    "            best_reg_param = reg_param\n",
    "            best_alpha = alpha\n",
    "        print(\"Accuracy = \", round(accuracy, 2), \" and Cost = \", round(J, 5), \" (\", reg_param, \", \", alpha, \")\", sep=\"\")\n",
    "print(\"Best:\", best_accuracy)\n",
    "print(\"Regularization:\", best_reg_param)\n",
    "print(\"Alpha:\", best_alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
